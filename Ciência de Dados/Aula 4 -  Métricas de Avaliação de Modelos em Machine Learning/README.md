# üìä M√©tricas de Avalia√ß√£o de Modelos em Machine Learning

## üìå Objetivos da Aula
- Entender como avaliar se um modelo de machine learning est√° funcionando bem
- Conhecer a matriz de confus√£o e suas m√©tricas principais
- Implementar um modelo simples e avaliar seu desempenho usando Python

## üîé Conceitos Fundamentais

### Matriz de Confus√£o
Uma tabela que nos mostra os acertos e erros do nosso modelo de classifica√ß√£o:

```
               ‚îÇ Predito Positivo ‚îÇ Predito Negativo
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Real Positivo  ‚îÇ     ACERTOU!     ‚îÇ      ERROU!
     (VP)      ‚îÇ                  ‚îÇ       (FN)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Real Negativo  ‚îÇ      ERROU!      ‚îÇ     ACERTOU!
     (FP)      ‚îÇ                  ‚îÇ       (VN)
```

## üéØ Analogias do Dia a Dia

### Matriz de Confus√£o = Boletim do Modelo
```
üìù Como ler as notas do seu modelo:

‚úÖ Verdadeiro Positivo = Acertou que era SPAM
‚ùå Falso Positivo = Disse que era SPAM, mas n√£o era
‚ùå Falso Negativo = N√£o viu o SPAM que existia
‚úÖ Verdadeiro Negativo = Acertou que n√£o era SPAM
```

### M√©tricas = Notas em Diferentes Mat√©rias
- **Acur√°cia** = Nota geral
- **Precis√£o** = Nota em n√£o dar alarmes falsos
- **Recall** = Nota em encontrar todos os problemas
- **F1-Score** = M√©dia entre precis√£o e recall

### M√©tricas Principais
- **Acur√°cia**: Porcentagem total de acertos do modelo
  - `(VP + VN) / Total`
- **Precis√£o**: Dos que o modelo disse que s√£o positivos, quantos realmente s√£o?
  - `VP / (VP + FP)`
- **Recall**: Dos casos realmente positivos, quantos o modelo encontrou?
  - `VP / (VP + FN)`
- **F1-Score**: Equil√≠brio entre precis√£o e recall
  - `2 * (Precis√£o * Recall) / (Precis√£o + Recall)`

## üíª Exemplo Pr√°tico em Python

```python
# Importar bibliotecas
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

# Criar um conjunto de dados simulado (para classifica√ß√£o)
X, y = make_classification(n_samples=1000, n_features=4, random_state=42)

# Dividir em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Criar e treinar o modelo
modelo = LogisticRegression()
modelo.fit(X_train, y_train)

# Fazer previs√µes
y_pred = modelo.predict(X_test)

# Calcular a matriz de confus√£o
conf_matrix = confusion_matrix(y_test, y_pred)
print("Matriz de Confus√£o:")
print(conf_matrix)

# Calcular m√©tricas
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"\nAcur√°cia: {accuracy:.2f}")
print(f"Precis√£o: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1-Score: {f1:.2f}")

# Visualizar a matriz de confus√£o
plt.figure(figsize=(8, 6))
plt.imshow(conf_matrix, cmap='Blues')
plt.title('Matriz de Confus√£o')
plt.colorbar()
plt.xlabel('Predito')
plt.ylabel('Real')
plt.xticks([0, 1], ['Negativo', 'Positivo'])
plt.yticks([0, 1], ['Negativo', 'Positivo'])

# Adicionar valores √† matriz
thresh = conf_matrix.max() / 2
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        plt.text(j, i, conf_matrix[i, j],
                 ha="center", va="center",
                 color="white" if conf_matrix[i, j] > thresh else "black")
plt.show()
```

## üéØ Atividade Pr√°tica para os Alunos

### Objetivo
Criar um modelo para classificar mensagens como spam ou n√£o-spam e avaliar seu desempenho.

### C√≥digo Base para os Alunos

```python
# Importar bibliotecas
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

# Criar um conjunto de dados simples (mensagens e classifica√ß√µes)
mensagens = [
    "PARAB√âNS! Voc√™ ganhou um iPhone gr√°tis!", 
    "Ol√°, tudo bem? Vamos nos encontrar amanh√£?",
    "URGENTE: Sua conta foi bloqueada. Clique aqui para desbloquear",
    "Lembrete: reuni√£o amanh√£ √†s 10h",
    "GANHE DINHEIRO R√ÅPIDO! Clique neste link agora!",
    "Oi, voc√™ deixou seu casaco aqui ontem",
    "PROMO√á√ÉO EXCLUSIVA: 70% de desconto em todos os produtos!",
    "Confirmo nosso almo√ßo de amanh√£",
    "ATEN√á√ÉO: √öltima chance para regularizar seu CPF!",
    "Me avisa quando chegar em casa"
]

# 0 = normal, 1 = spam
rotulos = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]

# Transformar textos em n√∫meros (vetoriza√ß√£o)
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(mensagens)
y = rotulos

# Dividir em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Criar e treinar o modelo
modelo = MultinomialNB()
modelo.fit(X_train, y_train)

# Fazer previs√µes
y_pred = modelo.predict(X_test)

# TODO: Calcular a matriz de confus√£o e as m√©tricas
# 1. Calcule a matriz de confus√£o
conf_matrix = ...

# 2. Calcule acur√°cia, precis√£o, recall e f1-score
acuracia = ...
precisao = ...
recall = ...
f1 = ...

# 3. Imprima os resultados
print("Matriz de Confus√£o:")
print(...)
print(f"Acur√°cia: {acuracia:.2f}")
print(f"Precis√£o: {precisao:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1-Score: {f1:.2f}")

# 4. B√îNUS: Teste o modelo com novas mensagens
novas_mensagens = [
    "Oi, como voc√™ est√°?",
    "CLIQUE AGORA E GANHE R$1000!"
]
# Transformar as novas mensagens
X_novas = ...
# Prever
previsoes = ...
# Mostrar resultados
for mensagem, previsao in zip(novas_mensagens, previsoes):
    resultado = "SPAM" if previsao == 1 else "N√ÉO SPAM"
    print(f"Mensagem: '{mensagem}' ‚Üí Classifica√ß√£o: {resultado}")
```

## üéÆ Exerc√≠cios Gamificados
Imagine que voc√™ √© um detetive de spam:
1. **N√≠vel 1**: Calcule a acur√°cia
2. **N√≠vel 2**: Descubra a precis√£o
3. **Boss Fight**: Equilibre precis√£o e recall

## üìù Exerc√≠cios de Avalia√ß√£o

1. **Complete as frases:**
   - A m√©trica que mede a propor√ß√£o total de acertos √© chamada de __________.
   - __________ mede a propor√ß√£o de exemplos positivos identificados corretamente.
   - Quando queremos equilibrar precis√£o e recall, usamos a m√©trica __________.

2. **Interpretando a Matriz:**
   Considere a seguinte matriz de confus√£o:
   ```
   [50  10]
   [5   35]
   ```
   a) Quantos verdadeiros positivos existem?
   b) Calcule a acur√°cia do modelo.
   c) Calcule a precis√£o do modelo.

3. **Quest√£o Pr√°tica:**
   No exemplo de detec√ß√£o de spam, por que o recall pode ser mais importante que a precis√£o? Ou a precis√£o pode ser mais importante que o recall? Explique.

4. **Desafio:**
   Modifique o c√≥digo da atividade pr√°tica adicionando pelo menos 5 novas mensagens (inventadas por voc√™) ao conjunto de dados. Como isso afeta as m√©tricas do modelo?

## üìö Dicas para Estudar para Concursos
- Memorize as f√≥rmulas das m√©tricas principais (acur√°cia, precis√£o, recall, F1)
- Entenda quando usar cada m√©trica (casos de classes desbalanceadas, custos diferentes de erro)
- Pratique o c√°lculo manual das m√©tricas a partir de uma matriz de confus√£o
- Saiba interpretar os resultados: um modelo com alta precis√£o e baixo recall significa que ele √© "conservador" (poucos falsos positivos)

## üéì Material de Refer√™ncia
- [Documenta√ß√£o do Scikit-learn sobre m√©tricas](https://scikit-learn.org/stable/modules/model_evaluation.html)
- [Guia ilustrado sobre matriz de confus√£o](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)