# ğŸ¯ RegularizaÃ§Ã£o e AvaliaÃ§Ã£o de Modelos em Machine Learning

## ğŸ“Œ Objetivos da Aula
- Compreender o conceito de regularizaÃ§Ã£o e sua importÃ¢ncia
- Conhecer os principais tipos de regularizaÃ§Ã£o (L1 e L2)
- Entender como evitar overfitting usando regularizaÃ§Ã£o
- Implementar modelos com regularizaÃ§Ã£o usando Python

## ğŸ” Conceitos Fundamentais

### Overfitting x Underfitting
- **Overfitting**: modelo "decorou" os dados de treino
- **Underfitting**: modelo muito simples, nÃ£o aprendeu o suficiente

### RegularizaÃ§Ã£o
TÃ©cnica para evitar overfitting adicionando penalidades aos parÃ¢metros do modelo.

### ğŸ“± Analogia Simples
Pense na regularizaÃ§Ã£o como um "controle parental" para seu modelo:
- **Sem regularizaÃ§Ã£o**: Modelo pode fazer o que quiser (memorizar tudo)
- **Com regularizaÃ§Ã£o**: Modelo tem limites e aprende o que Ã© realmente importante

### ğŸ® Exemplos do Dia a Dia
- **Overfitting** Ã© como decorar as respostas da prova sem entender a matÃ©ria
- **Underfitting** Ã© como chutar todas as respostas sem estudar
- **RegularizaÃ§Ã£o** Ã© como estudar de forma equilibrada

#### Tipos Principais
1. **L1 (Lasso)**
   - Adiciona |Î²| Ã  funÃ§Ã£o de custo
   - Pode zerar coeficientes (seleÃ§Ã£o de features)
   - Bom para features esparsas

2. **L2 (Ridge)**
   - Adiciona Î²Â² Ã  funÃ§Ã£o de custo
   - Diminui coeficientes, mas nÃ£o zera
   - Mais estÃ¡vel que L1

3. **Elastic Net**
   - Combina L1 e L2
   - Melhor dos dois mundos

## ğŸ’» Exemplo PrÃ¡tico em Python

```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, Lasso, ElasticNet
import matplotlib.pyplot as plt

# Criar dados sintÃ©ticos
np.random.seed(42)
X = np.random.randn(100, 20)  # 100 amostras, 20 features
y = X[:, 0] * 2 + X[:, 1] * (-1.5) + np.random.randn(100) * 0.1  # Apenas 2 features sÃ£o relevantes

# Dividir dados
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalizar dados
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Treinar modelos com diferentes regularizaÃ§Ãµes
modelos = {
    'Ridge': Ridge(alpha=1.0),
    'Lasso': Lasso(alpha=1.0),
    'ElasticNet': ElasticNet(alpha=1.0, l1_ratio=0.5)
}

# Treinar e avaliar cada modelo
for nome, modelo in modelos.items():
    # Treinar
    modelo.fit(X_train_scaled, y_train)
    
    # Avaliar
    score = modelo.score(X_test_scaled, y_test)
    print(f'\n{nome}:')
    print(f'RÂ² Score: {score:.3f}')
    print('Coeficientes diferentes de zero:', np.sum(modelo.coef_ != 0))
    
    # Visualizar coeficientes
    plt.figure(figsize=(10, 4))
    plt.bar(range(20), modelo.coef_)
    plt.title(f'Coeficientes do modelo {nome}')
    plt.xlabel('Feature')
    plt.ylabel('Coeficiente')
    plt.show()
```

## ğŸ¯ Atividade PrÃ¡tica para os Alunos

### Objetivo
Comparar diferentes tipos de regularizaÃ§Ã£o em um problema de previsÃ£o de preÃ§os de casas.

### Base de Dados
```python
from sklearn.datasets import fetch_california_housing

# Carregar dados
housing = fetch_california_housing()
X, y = housing.data, housing.target

# TODO: 
# 1. Dividir em treino/teste
# 2. Normalizar os dados
# 3. Treinar modelos com Ridge, Lasso e ElasticNet
# 4. Comparar resultados
# 5. Visualizar coeficientes
```

## ğŸ“ ExercÃ­cios TeÃ³ricos

1. O que Ã© regularizaÃ§Ã£o e por que Ã© importante?

2. Complete:
   - RegularizaÃ§Ã£o L1 Ã© conhecida como ________ e tende a ________ alguns coeficientes.
   - RegularizaÃ§Ã£o L2 Ã© conhecida como ________ e tende a ________ todos os coeficientes.

3. Qual a principal diferenÃ§a entre L1 e L2? Quando usar cada uma?

4. Como o parÃ¢metro alpha afeta a regularizaÃ§Ã£o?

## ğŸ”¬ QuestÃµes PrÃ¡ticas

1. **Caso PrÃ¡tico**: Em um modelo de previsÃ£o de vendas com 1000 features, muitas sÃ£o irrelevantes. Qual regularizaÃ§Ã£o vocÃª usaria e por quÃª?

2. **AnÃ¡lise**: Dado o grÃ¡fico de coeficientes abaixo, qual regularizaÃ§Ã£o foi provavelmente usada?
```
Coeficientes: [0, 2.5, 0, 1.8, 0, 0, 3.1, 0, 0, 0]
```

3. **ImplementaÃ§Ã£o**: Modifique o cÃ³digo da atividade prÃ¡tica para testar diferentes valores de alpha. Como isso afeta os resultados?

## ğŸ“ Conceitos-Chave para Memorizar

### RegularizaÃ§Ã£o L1 (Lasso)
- FÃ³rmula: L1 = Î£|Î²i|
- CaracterÃ­sticas:
  - SeleÃ§Ã£o de features
  - SoluÃ§Ã£o esparsa
  - Bom para features redundantes

### RegularizaÃ§Ã£o L2 (Ridge)
- FÃ³rmula: L2 = Î£(Î²i)Â²
- CaracterÃ­sticas:
  - Reduz multicolinearidade
  - SoluÃ§Ã£o mais estÃ¡vel
  - MantÃ©m todas as features

### Elastic Net
- FÃ³rmula: Î±(Î»||Î²||â‚ + (1-Î»)||Î²||â‚‚Â²)
- CaracterÃ­sticas:
  - Combina L1 e L2
  - Î» controla o mix
  - Mais flexÃ­vel

## ğŸ’¡ Dicas de Estudo
1. **Visualize os conceitos**:
   - L1 (Lasso) = âœ‚ï¸ Tesoura (corta features)
   - L2 (Ridge) = ğŸ”¨ Martelo (amassa valores)
   - Elastic Net = ğŸ› ï¸ Canivete suÃ­Ã§o (faz os dois)

2. **Quando usar cada tipo**:
   ```
   Muitas features irrelevantes? â†’ Use L1 (Lasso)
   Features correlacionadas? â†’ Use L2 (Ridge)
   NÃ£o tem certeza? â†’ Use Elastic Net
   ```

## ğŸ“š Material Extra
- [Scikit-learn: RegularizaÃ§Ã£o](https://scikit-learn.org/stable/modules/regularization.html)
- [Analytics Vidhya: RegularizaÃ§Ã£o](https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/)
- [Towards Data Science: L1 vs L2](https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c)
